{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5ZsIsqdPnr1",
        "outputId": "969cd162-27ee-4689-992a-723a10fd1050"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "oEjuOXUUhzAT"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, render_template_string, request, jsonify\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import pickle\n",
        "from io import BytesIO\n",
        "import traceback\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "import tensorflow\n",
        "import glob\n",
        "import cv2\n",
        "from skimage.metrics import structural_similarity as ssim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/template.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/template')"
      ],
      "metadata": {
        "id": "NRimDYPASiuA"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "last_conv_layer = base_model.get_layer('block5_pool').output\n",
        "x = GlobalAveragePooling2D()(last_conv_layer)\n",
        "x = Dense(4096, activation='relu')(x)  # Add a Dense layer with 4096 units\n",
        "feature_extractor = tensorflow.keras.Model(inputs=base_model.input, outputs=x)"
      ],
      "metadata": {
        "id": "4VZCmj0j-_HR"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/VGG16Epoch20poch.keras')"
      ],
      "metadata": {
        "id": "ritldi_ziyOU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/tokenizer.pkl', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "max_length = 34"
      ],
      "metadata": {
        "id": "MKqf6wMrjAgc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/features.pkl', 'rb') as f:\n",
        "    features = pickle.load(f)"
      ],
      "metadata": {
        "id": "RuhXC6tAs3V-"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)"
      ],
      "metadata": {
        "id": "7jSGGRisi9fz"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NGROK_AUTH_TOKEN = \"2pzJ3n8N6o3RVZ8fPxEtEgbkeFA_81N1eBZsukBB2cJmUrGu\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"Ngrok Tunnel URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1l7Ljp6-j_eD",
        "outputId": "9722a04f-0a91-4638-9817-dd1eb9cbb4fd"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok Tunnel URL: NgrokTunnel: \"https://2b98-34-148-70-236.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_templates(template_folder):\n",
        "    templates = []\n",
        "    for file_path in glob.glob(template_folder + \"/*.png\"):\n",
        "        template = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "        template = cv2.resize(template, (256, 256))\n",
        "        templates.append(template)\n",
        "    return templates"
      ],
      "metadata": {
        "id": "TekLjYfvU249"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_for_template_matching(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.resize(image, (256, 256))\n",
        "    return image"
      ],
      "metadata": {
        "id": "MdZDHORyU-jA"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_xray_image(image, templates, threshold=0.5):\n",
        "    for template in templates:\n",
        "        score, _ = ssim(image, template, full=True)\n",
        "        if score >= threshold:\n",
        "            return True  # Match found\n",
        "    return False"
      ],
      "metadata": {
        "id": "oTpMiTivVCH5"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_xray(image_path, template_folder):\n",
        "    templates = load_templates(template_folder)\n",
        "    image = preprocess_image_for_template_matching(image_path)\n",
        "    if is_xray_image(image, templates):\n",
        "        return \"Valid X-ray image\"\n",
        "    else:\n",
        "        return \"Invalid image. Not an X-ray.\""
      ],
      "metadata": {
        "id": "UYMj-JViVV7h"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def idx_to_word(integer, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == integer:\n",
        "            return word\n",
        "    return None"
      ],
      "metadata": {
        "id": "2VftZinpjCj9"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_for_captioning(image_path):\n",
        "  img = load_img(image_path, target_size=(224, 224))\n",
        "  img = img_to_array(img)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = preprocess_input(img)\n",
        "  features = feature_extractor.predict(img)\n",
        "  return features"
      ],
      "metadata": {
        "id": "2-8n7GPFVZpw"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_caption(model, image, tokenizer, max_length):\n",
        "    in_text = 'startseq'\n",
        "    for _ in range(max_length):\n",
        "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=150, padding='post')\n",
        "\n",
        "        # Assuming your model handles both image and sequence input\n",
        "        yhat = model.predict([image, sequence], verbose=0)\n",
        "\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = idx_to_word(yhat, tokenizer)\n",
        "        if word is None:\n",
        "            break\n",
        "        in_text += \" \" + word\n",
        "        if word == 'endseq':\n",
        "            break\n",
        "    return in_text"
      ],
      "metadata": {
        "id": "secBQb6kjHbC"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(file_path):  # Changed parameter to file_path\n",
        "    img = load_img(file_path, target_size=(224, 224))  # Use file_path here\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    features = feature_extractor.predict(img)\n",
        "    return features"
      ],
      "metadata": {
        "id": "vsetEmBQjLu-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/upload', methods=['POST'])\n",
        "def upload():\n",
        "    try:\n",
        "        if 'file' not in request.files:\n",
        "            raise ValueError('No file uploaded.')\n",
        "\n",
        "        file = request.files['file']\n",
        "        if file:\n",
        "            # 1. Save the uploaded file temporarily:\n",
        "            temp_file_path = os.path.join('/content', file.filename)  # Create a temporary file path\n",
        "            file.save(temp_file_path)  # Save the file\n",
        "\n",
        "            # 2. Validate the image using template matching:\n",
        "            validation_result = validate_xray(temp_file_path, '/content/template')  # Use temp_file_path\n",
        "            if validation_result == \"Valid X-ray image\":\n",
        "                # 3. Preprocess image using the saved file path:\n",
        "                features = preprocess_image(temp_file_path)  # Use temp_file_path\n",
        "\n",
        "                # Generate caption using your model and extracted features\n",
        "                caption = predict_caption(model, features, tokenizer, max_length)\n",
        "\n",
        "                return jsonify({'report': caption.replace('startseq', '').replace('endseq', '').strip()})\n",
        "            else:\n",
        "                return jsonify({'error': validation_result})  # Return error if not an X-ray\n",
        "\n",
        "        else:\n",
        "            raise ValueError('File processing error.')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        print(traceback.format_exc())\n",
        "        return jsonify({'error': f'Error generating report: {str(e)}'})"
      ],
      "metadata": {
        "id": "gULCAAMkjR7d"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string('''\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>X-Ray Report Generator</title>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            background-color: #121212;\n",
        "            color: #e0e0e0;\n",
        "        }\n",
        "        header {\n",
        "            background: #1f1f1f;\n",
        "            color: #76c7c0;\n",
        "            padding: 1rem 0;\n",
        "            text-align: center;\n",
        "        }\n",
        "        main {\n",
        "            max-width: 800px;\n",
        "            margin: 2rem auto;\n",
        "            padding: 1rem;\n",
        "            background: #1f1f1f;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.8);\n",
        "        }\n",
        "        h1 {\n",
        "            font-size: 2rem;\n",
        "            margin-bottom: 1rem;\n",
        "        }\n",
        "        .upload-section {\n",
        "            text-align: center;\n",
        "            margin-bottom: 2rem;\n",
        "        }\n",
        "        .upload-section input[type=\"file\"] {\n",
        "            margin-top: 1rem;\n",
        "            padding: 0.5rem;\n",
        "            border-radius: 5px;\n",
        "            border: 1px solid #555;\n",
        "            background-color: #2c2c2c;\n",
        "            color: #e0e0e0;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .image-preview {\n",
        "            margin: 2rem 0;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .image-preview img {\n",
        "            max-width: 100%;\n",
        "            height: auto;\n",
        "            border-radius: 8px;\n",
        "            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.8);\n",
        "        }\n",
        "        .report {\n",
        "            margin-top: 2rem;\n",
        "            text-align: center;\n",
        "        }\n",
        "        .report textarea {\n",
        "            width: 100%;\n",
        "            height: 150px;\n",
        "            padding: 1rem;\n",
        "            font-size: 1rem;\n",
        "            border: 1px solid #555;\n",
        "            border-radius: 8px;\n",
        "            background-color: #2c2c2c;\n",
        "            color: #e0e0e0;\n",
        "        }\n",
        "        .report button {\n",
        "            margin-top: 1rem;\n",
        "            padding: 0.8rem 2rem;\n",
        "            background-color: #76c7c0;\n",
        "            border: none;\n",
        "            border-radius: 5px;\n",
        "            color: #121212;\n",
        "            font-size: 1rem;\n",
        "            cursor: pointer;\n",
        "        }\n",
        "        .report button:hover {\n",
        "            background-color: #64b0a4;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <header>\n",
        "        <h1>X-Ray Report Generator</h1>\n",
        "    </header>\n",
        "    <main>\n",
        "        <section>\n",
        "            <h2 style=\"text-align: center; margin-bottom: 1rem;\">X-Ray Image Analysis</h2>\n",
        "        </section>\n",
        "        <section class=\"upload-section\">\n",
        "            <h2>Upload X-Ray Image</h2>\n",
        "            <input type=\"file\" id=\"fileInput\" accept=\"image/*\" onchange=\"handleFileUpload()\">\n",
        "        </section>\n",
        "        <section class=\"image-preview\" id=\"imagePreview\">\n",
        "            <h3>Uploaded Image Preview</h3>\n",
        "            <p>No image uploaded yet.</p>\n",
        "        </section>\n",
        "        <section class=\"report\">\n",
        "            <h3>Generated Report</h3>\n",
        "            <textarea id=\"report\" placeholder=\"The report will appear here after analysis...\"></textarea>\n",
        "            <button onclick=\"generateReport()\">Generate Report</button>\n",
        "        </section>\n",
        "    </main>\n",
        "    <script>\n",
        "        let uploadedFile = null;\n",
        "\n",
        "        function handleFileUpload() {\n",
        "            const fileInput = document.getElementById('fileInput');\n",
        "            const imagePreview = document.getElementById('imagePreview');\n",
        "            const report = document.getElementById('report');\n",
        "\n",
        "            uploadedFile = fileInput.files[0];\n",
        "\n",
        "            if (uploadedFile) {\n",
        "                const reader = new FileReader();\n",
        "                reader.onload = function (e) {\n",
        "                    imagePreview.innerHTML = `<img src=\"${e.target.result}\" alt=\"Uploaded X-Ray Image\">`;\n",
        "                    report.value = \"\"; // Clear the report text area\n",
        "                };\n",
        "                reader.readAsDataURL(uploadedFile);\n",
        "            } else {\n",
        "                imagePreview.innerHTML = '<p>No image uploaded yet.</p>';\n",
        "                report.value = '';\n",
        "            }\n",
        "        }\n",
        "\n",
        "        async function generateReport() {\n",
        "            const report = document.getElementById('report');\n",
        "            if (!uploadedFile) {\n",
        "                report.value = \"Please upload an X-Ray image first.\";\n",
        "                return;\n",
        "            }\n",
        "\n",
        "            const formData = new FormData();\n",
        "            formData.append('file', uploadedFile);\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/upload', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "\n",
        "                const data = await response.json();\n",
        "                if (data.report) {\n",
        "                    report.value = data.report;\n",
        "                } else {\n",
        "                    report.value = \"Error generating report.\";\n",
        "                }\n",
        "            } catch (error) {\n",
        "                console.error(error);\n",
        "                report.value = \"Error generating report.\";\n",
        "            }\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "    ''')"
      ],
      "metadata": {
        "id": "JVC2haQDjPaH"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    print(f\"Ngrok Tunnel URL: {public_url}\")\n",
        "    app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkNyIqZdjUHl",
        "outputId": "2f197273-0b47-4d57-9fbe-93efd6557018"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ngrok Tunnel URL: NgrokTunnel: \"https://2b98-34-148-70-236.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:16:15] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:16:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 864ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:16:35] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:16:48] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:17:03] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:17:21] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:17:35] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:17:53] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:18:09] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:18:23] \"POST /upload HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [10/Dec/2024 16:20:42] \"POST /upload HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qtq5KBiLjV1k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}